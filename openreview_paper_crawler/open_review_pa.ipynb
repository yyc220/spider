{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "955bdd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "数据已成功保存到 openreview_titles_abstracts.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "### request和beautiful soup是静态的 ###\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# OpenReview 的 URL\n",
    "url = \"https://openreview.net/group?id=ACM.org/TheWebConf/2025/Conference#tab-accept-oral\"\n",
    "\n",
    "# 设置请求头，模拟浏览器请求\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "}\n",
    "\n",
    "# 发送 HTTP 请求获取页面内容\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# 检查请求是否成功\n",
    "if response.status_code != 200:\n",
    "    print(f\"请求失败，状态码: {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "# 解析 HTML 内容\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# 打开一个 .txt 文件用于保存结果\n",
    "with open(\"openreview_titles_abstracts.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    # 查找所有文章的链接\n",
    "    paper_links = []\n",
    "\n",
    "    papers = soup.find_all(\"a\", href=True)  # 根据实际页面结构调整选择器\n",
    "\n",
    "    for paper in papers:\n",
    "        link = paper[\"href\"]\n",
    "        if \"/forum?id=\" in link:  # 确保链接是文章详情页\n",
    "            paper_links.append(\"https://openreview.net\" + link)\n",
    "    print(paper_links)\n",
    "\n",
    "    # 遍历每个文章的链接\n",
    "    for link in paper_links:\n",
    "        try:\n",
    "            # 发送 HTTP 请求获取文章详情页内容\n",
    "            paper_response = requests.get(link, headers=headers)\n",
    "            if paper_response.status_code != 200:\n",
    "                print(f\"无法获取文章页面: {link}\")\n",
    "                continue\n",
    "\n",
    "            # 解析文章详情页内容\n",
    "            paper_soup = BeautifulSoup(paper_response.text, \"html.parser\")\n",
    "\n",
    "            # 提取标题\n",
    "            title = paper_soup.find(\"h1\", class_=\"note-content-title\")\n",
    "            if title:\n",
    "                title = title.text.strip()\n",
    "            else:\n",
    "                title = \"未找到标题\"\n",
    "\n",
    "            # 提取摘要\n",
    "            abstract = paper_soup.find(\"div\", class_=\"note-content-abstract\")\n",
    "            if abstract:\n",
    "                abstract = abstract.text.strip()\n",
    "            else:\n",
    "                abstract = \"未找到摘要\"\n",
    "\n",
    "            # 将标题和摘要写入文件\n",
    "            file.write(f\"Title: {title}\\n\")\n",
    "            file.write(f\"Abstract: {abstract}\\n\")\n",
    "            file.write(\"-\" * 80 + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"爬取文章 {link} 时出错: {e}\")\n",
    "\n",
    "print(\"数据已成功保存到 openreview_titles_abstracts.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4421e425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到 openreview_titles_abstracts.md\n"
     ]
    }
   ],
   "source": [
    "### 动态 ###\n",
    "### 缺点：不支持所有页面内容提取，在单页中 没有筛选的全部文章都提取了\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import string\n",
    "\n",
    "# 配置 Selenium\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # 无头模式\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "# 创建selenium webdriver实例\n",
    "driver= webdriver.Chrome()\n",
    "\n",
    "### 只需更改此处 ###\n",
    "# 目标网址  \n",
    "url = \"https://openreview.net/group?id=ACM.org/TheWebConf/2025/Conference\"\n",
    "driver.get(url)\n",
    "\n",
    "# 等待页面加载\n",
    "time.sleep(5)\n",
    "\n",
    "# 获取所有论文的链接\n",
    "papers = driver.find_elements(By.CLASS_NAME, \"note\")  # 根据实际页面结构调整\n",
    "results = []\n",
    "links = []\n",
    "\n",
    "for paper in papers:\n",
    "    # 查找包含论坛链接的 a 标签\n",
    "    link_elem = paper.find_element(By.XPATH, \".//a[contains(@href, '/forum?')]\")  # 选择 href 包含 /forum? 的 a 标签\n",
    "    links.append(link_elem.get_attribute(\"href\"))  # 获取链接\n",
    "\n",
    "for i,link in zip(range(len(links)),links):     \n",
    "    # 访问该文章链接\n",
    "    driver.get(link)\n",
    "    # print(link)\n",
    "    if i % 60 != 0:\n",
    "        time.sleep(6)  # 等待页面加载\n",
    "    else:\n",
    "        time.sleep(20)\n",
    "    \n",
    "        # 提取标题和摘要\n",
    "    try:\n",
    "        meta_tag = driver.find_element(By.CSS_SELECTOR, 'meta[name=\"citation_title\"]')\n",
    "        title = meta_tag.get_attribute(\"content\")\n",
    "        meta_tag = driver.find_element(By.CSS_SELECTOR, 'meta[name=\"citation_abstract\"]')\n",
    "        abstract = meta_tag.get_attribute(\"content\")\n",
    "    except Exception as e:\n",
    "        title = \"未找到标题\"\n",
    "        abstract = \"未找到摘要\"\n",
    "        print(f\"无法获取文章信息: {e}\")\n",
    "        \n",
    "    # 将结果保存到列表\n",
    "    results.append(f\"## Title: {title}\\nAbstract: {abstract}\\n\")\n",
    "    \n",
    "    # 定义非法字符映射表，将其替换为 \"_\"\n",
    "    invalid_chars = '\\\\/*?:\"<>|'\n",
    "    translation_table = str.maketrans(invalid_chars, \"_\" * len(invalid_chars))\n",
    "    safe_title = title.translate(translation_table)\n",
    "\n",
    "    with open(f\"./tit_ab_files/{safe_title}.md\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(results[i])\n",
    "    \n",
    " # 关闭浏览器\n",
    "driver.quit()\n",
    "\n",
    "# 保存到文件\n",
    "with open(\"openreview_titles_abstracts.md\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"\\n\".join(results))\n",
    "\n",
    "print(\"数据已保存到 openreview_titles_abstracts.md\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7dadefa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无法找到下一页，爬取结束，Message: element not interactable\n",
      "  (Session info: chrome=120.0.6099.225)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF758072142+3514994]\n",
      "\t(No symbol) [0x00007FF757C90CE2]\n",
      "\t(No symbol) [0x00007FF757B374C3]\n",
      "\t(No symbol) [0x00007FF757B82D29]\n",
      "\t(No symbol) [0x00007FF757B76A0F]\n",
      "\t(No symbol) [0x00007FF757BA5FEA]\n",
      "\t(No symbol) [0x00007FF757B763B6]\n",
      "\t(No symbol) [0x00007FF757BA6490]\n",
      "\t(No symbol) [0x00007FF757BC28F6]\n",
      "\t(No symbol) [0x00007FF757BA5D93]\n",
      "\t(No symbol) [0x00007FF757B74BDC]\n",
      "\t(No symbol) [0x00007FF757B75C64]\n",
      "\tGetHandleVerifier [0x00007FF75809E16B+3695259]\n",
      "\tGetHandleVerifier [0x00007FF7580F6737+4057191]\n",
      "\tGetHandleVerifier [0x00007FF7580EE4E3+4023827]\n",
      "\tGetHandleVerifier [0x00007FF757DC04F9+689705]\n",
      "\t(No symbol) [0x00007FF757C9C048]\n",
      "\t(No symbol) [0x00007FF757C98044]\n",
      "\t(No symbol) [0x00007FF757C981C9]\n",
      "\t(No symbol) [0x00007FF757C888C4]\n",
      "\tBaseThreadInitThunk [0x00007FFC7818259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFC79E0AF38+40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 动态 ###\n",
    "### 修改\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import string\n",
    "\n",
    "# 配置 Selenium\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # 无头模式\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "# 创建selenium webdriver实例\n",
    "driver= webdriver.Chrome()\n",
    "\n",
    "### 只需更改此处 ###\n",
    "# 目标网址  \n",
    "url = \"https://openreview.net/group?id=ACM.org/TheWebConf/2025/Conference\"\n",
    "driver.get(url)\n",
    "page = 1\n",
    "# 等待页面加载\n",
    "time.sleep(5)\n",
    "\n",
    "while True:\n",
    "    # 获取所有论文的链接\n",
    "    accept_oral_div = driver.find_element(By.CSS_SELECTOR, \"div#accept-oral\")\n",
    "    papers = accept_oral_div.find_elements(By.CLASS_NAME, \"note\")  # 根据实际页面结构调整\n",
    "    results = []\n",
    "    links = []\n",
    "\n",
    "    for paper in papers:\n",
    "        # 查找包含论坛链接的 a 标签\n",
    "        link_elem = paper.find_element(By.XPATH, \".//a[contains(@href, '/forum?')]\")  # 选择 href 包含 /forum? 的 a 标签\n",
    "        links.append(link_elem.get_attribute(\"href\"))  # 获取链接\n",
    "\n",
    "    for i,link in zip(range(len(links)),links):     \n",
    "        # 访问该文章链接\n",
    "        driver.get(link)\n",
    "        time.sleep(5)\n",
    "\n",
    "            # 提取标题和摘要\n",
    "        try:\n",
    "            meta_tag = driver.find_element(By.CSS_SELECTOR, 'meta[name=\"citation_title\"]')\n",
    "            title = meta_tag.get_attribute(\"content\")\n",
    "            meta_tag = driver.find_element(By.CSS_SELECTOR, 'meta[name=\"citation_abstract\"]')\n",
    "            abstract = meta_tag.get_attribute(\"content\")\n",
    "        except Exception as e:\n",
    "            title = \"未找到标题\"\n",
    "            abstract = \"未找到摘要\"\n",
    "            print(f\"无法获取文章信息: {e}\")\n",
    "\n",
    "        # 将结果保存到列表\n",
    "        results = (f\"## Title: {title}\\nAbstract: {abstract}\\n\")\n",
    "\n",
    "        # 定义非法字符映射表，将其替换为 \"_\"\n",
    "        invalid_chars = '\\\\/*?:\"<>|'\n",
    "        translation_table = str.maketrans(invalid_chars, \"_\" * len(invalid_chars))\n",
    "        safe_title = title.translate(translation_table)\n",
    "\n",
    "        with open(f\"./tit_ab_files/{safe_title}.md\", \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(results)\n",
    "        \n",
    "    # 回到首页\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # 查找“下一页”按钮\n",
    "    try:\n",
    "        page = page + 1\n",
    "        next_button = driver.find_element(By.XPATH, f\"//a[text()= '{page}']\")\n",
    "        right_arrow = driver.find_element(By.XPATH, \"//li[@class='right-arrow']\")\n",
    "        if \"disabled\" in right_arrow.get_attribute(\"class\"):\n",
    "            print(\"没有更多页面，结束爬取\")\n",
    "            break\n",
    "        else:\n",
    "            next_button.click()\n",
    "            time.sleep(5)\n",
    "    except Exception as e:\n",
    "        print(f\"无法找到下一页，爬取结束，{e}\")\n",
    "        break\n",
    "                \n",
    "# 关闭浏览器\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ac2c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件内容已成功保存到 openreview_titles_abstracts.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 定义文件夹路径和输出文件路径\n",
    "input_folder = './tit_ab_files'\n",
    "output_file = 'openreview_titles_abstracts.md'\n",
    "\n",
    "# 打开输出文件，准备写入\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    # 遍历文件夹中的所有文件\n",
    "    for filename in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # 确保文件是一个普通文件而不是目录\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                # 打开并读取文件内容\n",
    "                with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                    content = infile.read()\n",
    "\n",
    "                    # 将文件内容写入输出文件\n",
    "                    outfile.write(f\"### {filename}\\n\\n\")\n",
    "                    outfile.write(content + \"\\n\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"无法读取文件 {filename}: {e}\")\n",
    "\n",
    "print(\"文件内容已成功保存到 openreview_titles_abstracts.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef675a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-python39] *",
   "language": "python",
   "name": "conda-env-conda-python39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
